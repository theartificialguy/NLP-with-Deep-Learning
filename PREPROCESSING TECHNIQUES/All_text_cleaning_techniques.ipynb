{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "All text cleaning techniques.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhxZmlk7yI5b"
      },
      "source": [
        "**TEXT CLEANING/PREPROCESSING TECHNIQUES IN NLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ao51mRowOwy"
      },
      "source": [
        "# importing necessary libraries\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "S91qkqu0wWXD",
        "outputId": "b3433d4f-3d95-49f1-d638-fb3f07f483dd"
      },
      "source": [
        "# importing/reading raw text data\n",
        "\n",
        "data = pd.read_csv(\"/content/SMSSpamCollection\", sep=\"\\t\", header=None)\n",
        "\n",
        "data.columns = [\"category\", \"text\"]\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgXypSHZwWSM",
        "outputId": "224d25ca-b10e-4f02-8ed6-5fa36e4dd3fe"
      },
      "source": [
        "data['category'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii5BlCc03uM8"
      },
      "source": [
        "**TECHNIQUE 1 :- TO LOWER CASE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Psg7ZqdjwWQN",
        "outputId": "d6c019ad-979a-4f0b-aca4-172bbe4d09c6"
      },
      "source": [
        "def convert_to_lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: convert_to_lower(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  go until jurong point, crazy.. available only ...\n",
              "1      ham                      ok lar... joking wif u oni...\n",
              "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3      ham  u dun say so early hor... u c already then say...\n",
              "4      ham  nah i don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Z_DN2e4I2J"
      },
      "source": [
        "**TECHNIQUE 2 :- REMOVING HTML TAGS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PzF-4b3EwWOC",
        "outputId": "3ebac9f9-4136-4a42-c28d-525f72f28517"
      },
      "source": [
        "import re\n",
        "\n",
        "punc = list(string.punctuation)\n",
        "\n",
        "def remove_html_tags(text):\n",
        "    html_pattern = r'<.*?>'\n",
        "    without_html = re.sub(pattern=html_pattern, repl=' ', string=text)\n",
        "    return without_html\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: remove_html_tags(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  go until jurong point, crazy.. available only ...\n",
              "1      ham                      ok lar... joking wif u oni...\n",
              "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3      ham  u dun say so early hor... u c already then say...\n",
              "4      ham  nah i don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jgyngkC68jM"
      },
      "source": [
        "**TECHNIQUE 3 :- REMOVING URLS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9jNfLO-twWLb",
        "outputId": "6212e98d-b46e-4fa0-876e-4a3b7b0c3467"
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_urls(text):\n",
        "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
        "    without_urls = re.sub(pattern=url_pattern, repl=' ', string=text)\n",
        "    return without_urls\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: remove_urls(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  go until jurong point, crazy.. available only ...\n",
              "1      ham                      ok lar... joking wif u oni...\n",
              "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3      ham  u dun say so early hor... u c already then say...\n",
              "4      ham  nah i don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5rr_iZZ792N"
      },
      "source": [
        "**TECHNIQUE 4 :- REMOVING NUMBERS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KzcnSElY5V8B",
        "outputId": "1beb9aa5-653e-421f-9627-b2f1411310ea"
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_numbers(text):\n",
        "    number_pattern = r'\\d+'\n",
        "    without_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
        "    return without_number\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: remove_numbers(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in   a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  go until jurong point, crazy.. available only ...\n",
              "1      ham                      ok lar... joking wif u oni...\n",
              "2     spam  free entry in   a wkly comp to win fa cup fina...\n",
              "3      ham  u dun say so early hor... u c already then say...\n",
              "4      ham  nah i don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO1XM1vM8apc"
      },
      "source": [
        "**TECHNIQUE 5 :- CONVERTING NUMBERS TO WORDS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "A5qpHDS65V4K",
        "outputId": "7ab0d0bd-b962-4603-95bd-0af660da25df"
      },
      "source": [
        "# !pip install num2words\n",
        "\n",
        "from num2words import num2words\n",
        "\n",
        "def convert_num_2_words(text):\n",
        "    splittedText = text.split()\n",
        "    for i in range(len(splittedText)):\n",
        "        if splittedText[i].isdigit():\n",
        "            splittedText[i] = num2words(splittedText[i])\n",
        "    num_2_words = ' '.join(splittedText)\n",
        "    return num_2_words\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: convert_num_2_words(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in two a wkly comp to win fa cup fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  go until jurong point, crazy.. available only ...\n",
              "1      ham                      ok lar... joking wif u oni...\n",
              "2     spam  free entry in two a wkly comp to win fa cup fi...\n",
              "3      ham  u dun say so early hor... u c already then say...\n",
              "4      ham  nah i don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAslRBJUFvM7"
      },
      "source": [
        "**TECHNIQUE 6 :- SPELLING CORRECTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30S5m_ZG5V1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a122a71-19a5-4e12-f731-ea405bb20ecd"
      },
      "source": [
        "# !pip install autocorrect\n",
        "\n",
        "from autocorrect import Speller\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def spell_checker(text):\n",
        "    spellChecker = Speller(lang=\"en\")\n",
        "    correct_words = []\n",
        "    for word in nltk.word_tokenize(text):\n",
        "        correct_word = spellChecker(word)\n",
        "        correct_words.append(correct_word)\n",
        "    correct_spell_text = \" \".join(correct_words)\n",
        "    return correct_spell_text\n",
        "\n",
        "example_text = \"tihs is a expmle of spel chekcer\"\n",
        "print(f\"Original sentence: {example_text}\")\n",
        "print(f\"Autocorrect sentence: {spell_checker(example_text)}\")\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: spell_checker(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence: tihs is a expmle of spel chekcer\n",
            "Autocorrect sentence: this is a example of spell checker\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJS7JpmUH1fo"
      },
      "source": [
        "**TECHNIQUE 7 :- CONVERTING ACCENTED CHARS TO ASCII CHARS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKDj2h7m5Vy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e11db4b-c205-4fd4-8e08-038c6cd9dc1c"
      },
      "source": [
        "# !pip install unidecode\n",
        "\n",
        "import unidecode\n",
        "\n",
        "def convert_accented_2_ascii(text):\n",
        "    return unidecode.unidecode(text)\n",
        "\n",
        "example_text = \"This is an example text with accented characters like d√®√®p l√®arning √°nd c√∂mputer v√≠s√≠√∂n etc\"\n",
        "print(f\"Original sentence: {example_text}\")\n",
        "print(f\"Converted sentence: {convert_accented_2_ascii(example_text)}\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence: This is an example text with accented characters like d√®√®p l√®arning √°nd c√∂mputer v√≠s√≠√∂n etc\n",
            "Converted sentence: This is an example text with accented characters like deep learning and computer vision etc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSbAvHcwIjPu"
      },
      "source": [
        "**TECHNIQUE 8 :- EXPANDING CONTRACTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e2vGkRh5Vwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f1a7f7-c772-46e1-ba7a-0f23bd86c5b1"
      },
      "source": [
        "# !pip install contractions\n",
        "\n",
        "import contractions\n",
        "\n",
        "def expand_contractions(text):\n",
        "    expanded_text = []\n",
        "    for word in text.split():\n",
        "        expanded_text.append(contractions.fix(word))\n",
        "    return \" \".join(expanded_text)\n",
        "\n",
        "example_text = \"Sometimes our mind doesn't work properly. I've tried everything.\"\n",
        "print(f\"Original text: {example_text}\")\n",
        "print(f\"Expanded text: {expand_contractions(example_text)}\")"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text: Sometimes our mind doesn't work properly. I've tried everything.\n",
            "Expanded text: Sometimes our mind does not work properly. I have tried everything.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKkYwRGZLVHl"
      },
      "source": [
        "**TECHNIQUE 9 :- STEMMING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTioOatz5VuD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8d8124ce-24c0-45ae-cdf8-8c69a5c8165d"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk import word_tokenize\n",
        "\n",
        "def stemming(text):\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        stem_word = stemmer.stem(tokens[i])\n",
        "        tokens[i] = stem_word\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: stemming(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point , crazy.. avail onli in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar ... joke wif u oni ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entri in two a wkli comp to win fa cup fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so earli hor ... u c alreadi then sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i do n't think he goe to usf , he live aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  go until jurong point , crazy.. avail onli in ...\n",
              "1      ham                      ok lar ... joke wif u oni ...\n",
              "2     spam  free entri in two a wkli comp to win fa cup fi...\n",
              "3      ham  u dun say so earli hor ... u c alreadi then sa...\n",
              "4      ham  nah i do n't think he goe to usf , he live aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L8ZJflwM3C4"
      },
      "source": [
        "**TECHNIQUE 10 :- LEMMATIZING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RxJK0Nc5VrO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5e96581e-3242-4a14-a058-b1bc2204bd2f"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "def lemmatizing(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        lemma_word = lemmatizer.lemmatize(tokens[i])\n",
        "        tokens[i] = lemma_word\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: lemmatizing(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point , crazy.. avail onli in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar ... joke wif u oni ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entri in two a wkli comp to win fa cup fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so earli hor ... u c alreadi then sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i do n't think he goe to usf , he live aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  go until jurong point , crazy.. avail onli in ...\n",
              "1      ham                      ok lar ... joke wif u oni ...\n",
              "2     spam  free entri in two a wkli comp to win fa cup fi...\n",
              "3      ham  u dun say so earli hor ... u c alreadi then sa...\n",
              "4      ham  nah i do n't think he goe to usf , he live aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsSGmzuGNyco"
      },
      "source": [
        "**TECHNIQUE 11 :- EMOJI REMOVAL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnhrKeph5Vox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb11b84-e681-4b43-dd37-878b3024a9c1"
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\U0001f926-\\U0001f937\"\n",
        "                               u\"\\U00010000-\\U0010ffff\"\n",
        "                               u\"\\u2640-\\u2642\"\n",
        "                               u\"\\u2600-\\u2B55\"\n",
        "                               u\"\\u200d\"\n",
        "                               u\"\\u23cf\"\n",
        "                               u\"\\u23e9\"\n",
        "                               u\"\\u231a\"\n",
        "                               u\"\\ufe0f\"  # dingbats\n",
        "                               u\"\\u3030\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    removeEmoji = emoji_pattern.sub(r'', text)\n",
        "    return removeEmoji\n",
        "\n",
        "example_text = \"This is a test üòª \"\n",
        "print(f\"Original text: {example_text}\")\n",
        "print(f\"Removed emoji: {remove_emoji(example_text)}\")"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text: This is a test üòª \n",
            "Removed emoji: This is a test  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaCMFWCTOjtx"
      },
      "source": [
        "**TECHNIQUE 12 :- EMOTICONS REMOVAL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlYh-nGi5VmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "777de6b3-4072-4fa2-8195-f3a3b71974c0"
      },
      "source": [
        "from emo_unicode import *\n",
        "\n",
        "def remove_emoticons(text):\n",
        "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n",
        "    without_emoticons = emoticon_pattern.sub(r'', text)\n",
        "    return without_emoticons\n",
        "\n",
        "example_text = \"This is a test :) yooo *_* \"\n",
        "print(f\"Original text: {example_text}\")\n",
        "print(f\"Removed emoticons: {remove_emoticons(example_text)}\")"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text: This is a test :) yooo *_* \n",
            "Removed emoticons: This is a test  yooo *_* \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e4SpsuXP17x"
      },
      "source": [
        "**TECHNIQUE 13 :- REMOVING PUNCTUATIONS OR SPECIAL CHARS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctmLpanq5VjS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e9ddc8d5-a38a-4e6f-bf47-24a402221f33"
      },
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: remove_punctuation(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point  crazy avail onli in bug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar  joke wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entri in two a wkli comp to win fa cup fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so earli hor  u c alreadi then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i do nt think he goe to usf  he live aroun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  go until jurong point  crazy avail onli in bug...\n",
              "1      ham                            ok lar  joke wif u oni \n",
              "2     spam  free entri in two a wkli comp to win fa cup fi...\n",
              "3      ham      u dun say so earli hor  u c alreadi then say \n",
              "4      ham  nah i do nt think he goe to usf  he live aroun..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTE0ISLuRBcK"
      },
      "source": [
        "**TECHNIQUE 14 :- REMOVING STOPWORDS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JboTYmaCOjUd",
        "outputId": "1b74a2f9-a1f1-4f6c-e92a-6c4831d53130"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    removed = []\n",
        "    stop_words = list(stopwords.words(\"english\"))\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        if tokens[i] not in stop_words:\n",
        "            removed.append(tokens[i])\n",
        "    return \" \".join(removed)\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go jurong point crazy avail onli bugi n great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar joke wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entri two wkli comp win fa cup final tkt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say earli hor u c alreadi say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah nt think goe usf live around though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  go jurong point crazy avail onli bugi n great ...\n",
              "1      ham                              ok lar joke wif u oni\n",
              "2     spam  free entri two wkli comp win fa cup final tkt ...\n",
              "3      ham                u dun say earli hor u c alreadi say\n",
              "4      ham            nah nt think goe usf live around though"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNviFcIWSROt"
      },
      "source": [
        "**TECHNIQUE 15 :- REMOVING FREQUENT WORDS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_yL-EHoOjQX"
      },
      "source": [
        "from collections import Counter\n",
        "from nltk import word_tokenize\n",
        "\n",
        "counter = Counter()\n",
        "\n",
        "# first a function that will find most common/frequent words in a corpus\n",
        "def findMostFrequentWords(corpus):\n",
        "    tokens = word_tokenize(corpus)\n",
        "    for word in tokens:\n",
        "        counter[word] += 1\n",
        "    freq_words = []\n",
        "    for (word, word_count) in counter.most_common(10):\n",
        "        freq_words.append(word)\n",
        "    return freq_words\n",
        "\n",
        "# now remove the most common/frequent words from text\n",
        "def remove_frequent_words(freq_words, text):\n",
        "    without_freq_words = []\n",
        "    tokens = word_tokenize(text)\n",
        "    for word in tokens:\n",
        "        if word not in freq_words:\n",
        "            without_freq_words.append(word)\n",
        "    return \" \".join(without_freq_words)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UqlMLIDUe1A"
      },
      "source": [
        "**TECHNIQUE 16 :- REMOVING RARE WORDS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQs_QrHEOjN7"
      },
      "source": [
        "from collections import Counter\n",
        "from nltk import word_tokenize\n",
        "\n",
        "counter = Counter()\n",
        "\n",
        "def findRareWords(corpus):\n",
        "    tokens = word_tokenize(corpus)\n",
        "    for word in tokens:\n",
        "        counter[word] += 1\n",
        "    rare_words = []\n",
        "    num_rare_words = 10\n",
        "    frequentWords = counter.most_common()\n",
        "\tfor (word, word_count) in frequentWords[:-num_rare_words:-1]:\n",
        "\t\trare_words.append(word)\n",
        "    return rare_words\n",
        "\n",
        "def remove_rare_words(rare_words, text):\n",
        "    without_rare_words = []\n",
        "    tokens = word_tokenize(text)\n",
        "    for word in tokens:\n",
        "        if word not in rare_words:\n",
        "            without_rare_words.append(word)\n",
        "    return \" \".join(without_rare_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MReXGCHVVLow"
      },
      "source": [
        "**TECHNIQUE 17 :- REMOVING SINGLE CHARS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uFOEHQo6OjLu",
        "outputId": "bec976ad-20a9-4a17-a607-1aa38df7da42"
      },
      "source": [
        "def remove_single_chars(text):\n",
        "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
        "    without_single_char = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
        "    return without_single_char\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: remove_single_chars(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go jurong point crazy avail onli bugi great wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar joke wif oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entri two wkli comp win fa cup final tkt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say earli hor c alreadi say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah nt think goe usf live around though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  go jurong point crazy avail onli bugi great wo...\n",
              "1      ham                                ok lar joke wif oni\n",
              "2     spam  free entri two wkli comp win fa cup final tkt ...\n",
              "3      ham                  u dun say earli hor c alreadi say\n",
              "4      ham            nah nt think goe usf live around though"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03bzUjwqVhnR"
      },
      "source": [
        "**TECHNIQUE 18 :- REMOVING EXTRA WHITE SPACES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zeIeFQuMOjJe",
        "outputId": "3e05950f-1c03-4dbb-8a70-d3652435a30a"
      },
      "source": [
        "def remove_extra_white_spaces(text):\n",
        "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
        "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
        "    return without_sc\n",
        "\n",
        "data[\"text\"] = data[\"text\"].apply(lambda x: remove_extra_white_spaces(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go jurong point crazy avail onli bugi great wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar joke wif oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entri two wkli comp win fa cup final tkt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say earli hor alreadi say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah nt think goe usf live around though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text\n",
              "0      ham  go jurong point crazy avail onli bugi great wo...\n",
              "1      ham                                ok lar joke wif oni\n",
              "2     spam  free entri two wkli comp win fa cup final tkt ...\n",
              "3      ham                    u dun say earli hor alreadi say\n",
              "4      ham            nah nt think goe usf live around though"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    }
  ]
}